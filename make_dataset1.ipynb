{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c6370a01",
   "metadata": {},
   "source": [
    "### Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eefd9806",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "db5d5d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys  \n",
    "sys.path.insert(0, 'human_activity_recognition--main/new')\n",
    "from pose_media import mediapipe_pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5e48597a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"./DATA/\" \n",
    "if not os.path.exists(DATA_PATH):\n",
    "    os.mkdir(DATA_PATH)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e4998dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mp = mediapipe_pose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "41012635",
   "metadata": {},
   "outputs": [],
   "source": [
    "cTime,pTime = 0,0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25f5aeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 30\n",
    "path = 'C:/Users/sanka/OneDrive/Desktop/Minor_project/Dataset/depth/'\n",
    "actions = os.listdir(path)\n",
    "for action in actions:\n",
    "    if not os.path.exists(DATA_PATH+action):\n",
    "        os.mkdir(DATA_PATH+action)\n",
    "    video_list = os.listdir(path+action)\n",
    "    no_sequences = 1776//len(video_list)\n",
    "    extra_sequences = 1776%len(video_list)\n",
    "    for video in range(len(video_list)):\n",
    "        cd = os.path.join(path+ action+\"/\" + video_list[video])\n",
    "        cap = cv2.VideoCapture(cd)\n",
    "        with mp.mp_holistic.Holistic(min_detection_confidence=0.5, min_tracking_confidence=0.5) as holistic:\n",
    "            if video < extra_sequences:\n",
    "                no_sequences += 1\n",
    "                pre_sequences = video * no_sequences \n",
    "            elif video == extra_sequences:\n",
    "                pre_sequences = video * (no_sequences +1)\n",
    "            else:\n",
    "                pre_sequences = extra_sequences * (no_sequences +1) + (video - extra_sequences)*no_sequences\n",
    "            for sequence in range(no_sequences):\n",
    "                if not os.path.exists(DATA_PATH+action+\"/\"+str(pre_sequences+sequence)):\n",
    "                    os.mkdir(DATA_PATH+action+\"/\"+str(pre_sequences+sequence))\n",
    "                for frame_num in range(sequence_length):\n",
    "                        ref,frame = cap.read()\n",
    "                        try:\n",
    "                            image, results = mp.mediapipe_detection(frame, holistic)\n",
    "                        except:\n",
    "                            break\n",
    "                            \n",
    "                        mp.draw_styled_landmarks(image, results)\n",
    "                        cTime = time.time()\n",
    "                        fps = 1 / (cTime - pTime)\n",
    "                        pTime = cTime\n",
    "                        cv2.putText(image,\"FPS:\" +str(int(fps)),(10,100), cv2.FONT_HERSHEY_PLAIN, 2,(255,0,190),2,cv2.LINE_AA)\n",
    "\n",
    "                        if frame_num == 0: \n",
    "                            cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action, video), (5,15), \n",
    "                                              cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                            cv2.imshow('OpenCV Feed', image)\n",
    "                        else: \n",
    "                            cv2.putText(image, 'Collecting frames for {} Video Number {}'.format(action,video), (5,15), \n",
    "                                            cv2.FONT_HERSHEY_SIMPLEX, 0.3, (0, 0, 255), 1, cv2.LINE_AA)\n",
    "                            cv2.imshow('OpenCV Feed', image)\n",
    "\n",
    "                        keypoints = mp.extract_keypoints(results)\n",
    "                        npy_path = os.path.join(DATA_PATH, action, str(pre_sequences+sequence), str(frame_num))\n",
    "                        np.save(npy_path, keypoints)\n",
    "                        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "                            break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0a109293",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = os.path.join('human_activity_recognition--main\\\\DATA') \n",
    "actions = np.array([\"Salute\",\"Sitting\"])\n",
    "no_sequences = 1776\n",
    "sequence_length = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a391b6d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Salute': 0, 'Sitting': 1}"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_map = {label:num for num,label in enumerate(actions)}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "597f1c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(actions,no_sequences,sequence_length):\n",
    "    sequences1,labels = [],[]\n",
    "    for action in actions:\n",
    "        for sequence in range(no_sequences):\n",
    "            window = []\n",
    "            for frame_num in range(sequence_length):\n",
    "                res = np.load(os.path.join(DATA_PATH,action,str(sequence),\"{}.npy\".format(frame_num)))\n",
    "                window.append(res)\n",
    "            sequences1.append(window)\n",
    "            labels.append(label_map[action])\n",
    "    return sequences1,labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "bce52a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences,labels = [],[]\n",
    "# for action in os.listdir(\"xxx/\"):\n",
    "#     fd = os.path.join(\"xxx/\" + action)\n",
    "#     window = []\n",
    "#     for folder in os.listdir(fd):\n",
    "#         fd1 = os.path.join(\"xxx/\" + action +\"/\"+ folder)\n",
    "#         for file in os.listdir(fd1):\n",
    "#             res = np.load(os.path.join(\"xxx/\" + action +\"/\"+ folder + \"/\" + file))\n",
    "#             window.append(res)\n",
    "#         sequences.append(window)\n",
    "#         labels.append(label_map[action])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "0cb15b1a",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'human_activity_recognition--main\\\\DATA\\\\Salute\\\\0\\\\0.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32m<timed exec>:1\u001b[0m\n",
      "Cell \u001b[1;32mIn [87], line 7\u001b[0m, in \u001b[0;36mload_data\u001b[1;34m(actions, no_sequences, sequence_length)\u001b[0m\n\u001b[0;32m      5\u001b[0m window \u001b[39m=\u001b[39m []\n\u001b[0;32m      6\u001b[0m \u001b[39mfor\u001b[39;00m frame_num \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(sequence_length):\n\u001b[1;32m----> 7\u001b[0m     res \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39;49mload(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(DATA_PATH,action,\u001b[39mstr\u001b[39;49m(sequence),\u001b[39m\"\u001b[39;49m\u001b[39m{}\u001b[39;49;00m\u001b[39m.npy\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(frame_num)))\n\u001b[0;32m      8\u001b[0m     window\u001b[39m.\u001b[39mappend(res)\n\u001b[0;32m      9\u001b[0m sequences1\u001b[39m.\u001b[39mappend(window)\n",
      "File \u001b[1;32mc:\\Users\\sanka\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\numpy\\lib\\npyio.py:417\u001b[0m, in \u001b[0;36mload\u001b[1;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[0;32m    415\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    416\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 417\u001b[0m     fid \u001b[39m=\u001b[39m stack\u001b[39m.\u001b[39menter_context(\u001b[39mopen\u001b[39;49m(os_fspath(file), \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m))\n\u001b[0;32m    418\u001b[0m     own_fid \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    420\u001b[0m \u001b[39m# Code to distinguish from NumPy binary files and pickles.\u001b[39;00m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'human_activity_recognition--main\\\\DATA\\\\Salute\\\\0\\\\0.npy'"
     ]
    }
   ],
   "source": [
    "%time sequences,labels = load_data(actions,no_sequences,sequence_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b7156747",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sequences' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [90], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(sequences)\n\u001b[0;32m      2\u001b[0m X\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'sequences' is not defined"
     ]
    }
   ],
   "source": [
    "X = np.array(sequences)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "92f31566",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'labels' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [91], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m y \u001b[39m=\u001b[39m to_categorical(labels)\u001b[39m.\u001b[39mastype(\u001b[39mint\u001b[39m)\n\u001b[0;32m      2\u001b[0m y\n",
      "\u001b[1;31mNameError\u001b[0m: name 'labels' is not defined"
     ]
    }
   ],
   "source": [
    "y = to_categorical(labels).astype(int)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "cf0aeaa0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [92], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mX1.npy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[1;32m----> 2\u001b[0m     np\u001b[39m.\u001b[39msave(f, X)\n\u001b[0;32m      3\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39m(\u001b[39m'\u001b[39m\u001b[39my1.npy\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwb\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m      4\u001b[0m     np\u001b[39m.\u001b[39msave(f, y)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "with open('X1.npy', 'wb') as f:\n",
    "    np.save(f, X)\n",
    "with open('y1.npy', 'wb') as f:\n",
    "    np.save(f, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085ac43c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "b395237ac961518af87e98e950601cbd837c5d3c01a15f716a4dac1afef369d7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
